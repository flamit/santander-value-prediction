{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0v0: Light GBM\n",
    "Model 0v0 will explore the utility of using a Light GBM regressor that features extensive parameter tuning and averaging of multiple models. The inspiration for this notebook is taken from a portion of this Kaggle public kernel: https://www.kaggle.com/prashantkikani/ensembling-has-always-been-the-answer/code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load h5py file\n",
    "def loadh5(fname, dname):\n",
    "    h5f = h5py.File(fname, 'r')\n",
    "    data = h5f[dname][:]\n",
    "    h5f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "def loadpickle(fname):\n",
    "    with open(fname, 'rb') as handle:\n",
    "        data = pkl.load(handle)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "train_dname = 'train_s0'\n",
    "test_dname = 'test_s0'\n",
    "f_ext = '_vanilla.h5'\n",
    "\n",
    "# Load h5py data\n",
    "train_data = loadh5(data_path + train_dname + f_ext, train_dname)\n",
    "test_data = loadh5(data_path + test_dname + f_ext, test_dname)\n",
    "# Load dataframe indexes\n",
    "train_idx = loadpickle(data_path + 'train_idx.pkl')\n",
    "test_idx = loadpickle(data_path + 'test_idx.pkl')\n",
    "# Load dataframe column names\n",
    "train_cols = loadpickle(data_path + 'train_cols.pkl')\n",
    "test_cols = loadpickle(data_path + 'test_cols.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes\n",
    "train_df = pd.DataFrame(data=train_data, index=train_idx, columns=train_cols)\n",
    "test_df = pd.DataFrame(data=test_data, index=test_idx, columns=test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the training labels\n",
    "labels = train_df.target\n",
    "train_df.drop(columns=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of training dataset: {} Rows, {} Columns'.format(*train_df.shape))\n",
    "print('Shape of test dataset: {} Rows, {} Columns'.format(*test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Data for Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_labels = np.log1p(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(train_df, log_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM Regressor:\n",
    "Process Flow for Light GBM Regressor Training:\n",
    "* Find optimal number of rounds for a larger learning rate\n",
    "* Find optimal number of rounds for smaller learning rates\n",
    "* Find the optimal number of rounds and best parameters out of the trials above\n",
    "* Run a final model with different seed initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(train_df, label=log_labels, feature_name='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Rounds', 'Score', 'STD', 'LB', 'Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 200,\n",
    "    \"feature_fraction\": 0.50,\n",
    "    \"bagging_fraction\": 0.50,\n",
    "    'bagging_freq': 4,\n",
    "    \"max_depth\": -1,  # No limit on tree depth\n",
    "    \"lambda_l1\": 0.3,\n",
    "    \"lambda_l2\": 0.1,\n",
    "    \"min_sum_hessian_in_leaf\": 10,\n",
    "    'zero_as_missing': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal parameters / boosting rounds (larger learning rate)\n",
    "lgb_cv = lgb.cv(\n",
    "    params = lgbm_params,\n",
    "    train_set = lgtrain,\n",
    "    num_boost_round=2500,\n",
    "    stratified=False,\n",
    "    nfold = 5,\n",
    "    verbose_eval=50,\n",
    "    seed = 23,\n",
    "    early_stopping_rounds=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "print('Optimal Round: {}\\nOptimal Score: {} + {}'.format(optimal_rounds, best_cv_score, \n",
    "                                                         lgb_cv['rmse-stdv'][optimal_rounds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to results dataframe\n",
    "results = results.append({'Rounds': optimal_rounds,\n",
    "                          'Score': best_cv_score,\n",
    "                          'STD': lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                          'LB': None,\n",
    "                          'Parameters': lgbm_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal parameters / boosting rounds (smaller learning rate)\n",
    "learning_rates = [0.012, 0.008, 0.016]\n",
    "for param in learning_rates:\n",
    "    print 'Learning rate:', param\n",
    "    lgbm_params['learning_rate'] = param\n",
    "    # Get cross validated results\n",
    "    lgb_cv = lgb.cv(\n",
    "        params = lgbm_params,\n",
    "        train_set = lgtrain,\n",
    "        num_boost_round= 10000,\n",
    "        stratified= False,\n",
    "        nfold = 5,\n",
    "        verbose_eval= 200,\n",
    "        seed = 23,\n",
    "        early_stopping_rounds= 75)\n",
    "    optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "    best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "    print('Optimal Round: {}\\nOptimal Score: {} + {}'.format(optimal_rounds, best_cv_score, \n",
    "                                                         lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "    # Append results to results dataframe\n",
    "    results = results.append({'Rounds': optimal_rounds,\n",
    "                              'Score': best_cv_score,\n",
    "                              'STD': lgb_cv['rmse-stdv'][optimal_rounds],\n",
    "                              'LB': None,\n",
    "                              'Parameters': lgbm_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_params = results.iloc[results['Score'].idxmin(), :]['Parameters']\n",
    "optimal_rounds = results.iloc[results['Score'].idxmin(), :]['Rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with different seeds\n",
    "multi_seed_pred = dict()\n",
    "all_feature_importance_list = []\n",
    "all_seeds = [27, 22, 300, 401, 7]\n",
    "for seed in all_seeds:\n",
    "    print 'Seed:', seed\n",
    "    final_model_params['seed'] = seed\n",
    "    lgb_reg = lgb.train(final_model_params,\n",
    "                        lgtrain,\n",
    "                        num_boost_round = optimal_rounds+1,\n",
    "                        verbose_eval = 200)\n",
    "    all_feature_importance_list.append((train_cols, lgb_reg.feature_importance()))\n",
    "    # Predict on test data\n",
    "    multi_seed_pred[seed] = list(lgb_reg.predict(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = pd.DataFrame.from_dict(multi_seed_pred).replace(0, 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sub = np.expm1(sub_preds.mean(axis=1)).rename('target')\n",
    "mean_sub.index = test_idx\n",
    "mean_sub.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submission file\n",
    "mean_sub.to_csv('../submissions/lgb_0v0_submit.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
