{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0 Data Exploration & Preprocessing (Vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 0 data exploration will aim to yield an introductory understanding of the Santander Value Prediction dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import h5py\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "train_df = pd.read_csv(data_path + 'train.csv', index_col='ID')\n",
    "test_df = pd.read_csv(data_path + 'test.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of train dataframe: {} Rows, {} Columns'.format(*train_df.shape))\n",
    "print('Shape of test dataframe: {} Rows, {} Columns'.format(*test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the training labels\n",
    "labels = train_df.target\n",
    "train_df.drop(columns=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of null values \n",
    "print 'Number of null values in training set:', train_df.isnull().sum().sum()\n",
    "print 'Number of null values in test set:', test_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sparsity of dataset\n",
    "def how_sparse(df):\n",
    "    num_nonzero = df.astype(bool).sum(axis=0).sum()\n",
    "    return(100 * num_nonzero/float(df.shape[0] * df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Sparsity of training data (in percent):', how_sparse(train_df)\n",
    "print 'Sparsity of test data (in percent):', how_sparse(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns have constant values? \n",
    "def is_constant(df):\n",
    "    constant = []\n",
    "    for column in df.columns.values:\n",
    "        if len(df[column].unique()) == 1:\n",
    "            constant.append(column)\n",
    "    return(constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Number of columns with constant values in train dataset:', len(is_constant(train_df))\n",
    "print 'Number of columns with constant values in test dataset:', len(is_constant(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, there are 256 columns in the training dataset that have constant values while there are 0 columns in the test dataset. This behavior is most likely due to the test dataset having almost 10x more samples than the training dataset. During the data preprocessing stage, the 256 columns with constant values will need to be removed from both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = is_constant(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant columns\n",
    "train_df.drop(columns=drop_cols, axis=1, inplace=True)\n",
    "test_df.drop(columns=drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of training dataset: {} Rows, {} Columns'.format(*train_df.shape))\n",
    "print('Shape of test dataset: {} Rows, {} Columns'.format(*test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicate columns\n",
    "def get_duplicates(df):\n",
    "    groups = df.columns.to_series().groupby(df.dtypes).groups\n",
    "    dups = []\n",
    "    \n",
    "    for t, v in groups.items():\n",
    "        cs = df[v].columns\n",
    "        vs = df[v]\n",
    "        lcs = len(cs)\n",
    "        \n",
    "        for i in range(lcs):\n",
    "            ia = vs.iloc[:, i].values\n",
    "            for j in range(i+1, lcs):\n",
    "                ja = vs.iloc[:, j].values\n",
    "                if np.array_equal(ia, ja):\n",
    "                    dups.append(cs[i])\n",
    "    return dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cols = get_duplicates(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Duplicate columns:\\n', set(duplicate_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns\n",
    "train_df.drop(list(set(duplicate_cols)), axis=1, inplace=True)\n",
    "test_df.drop(list(set(duplicate_cols)), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of training dataset: {} Rows, {} Columns'.format(*train_df.shape))\n",
    "print('Shape of test dataset: {} Rows, {} Columns'.format(*test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(data=labels)\n",
    "labeled_train = pd.concat([train_df, label_df], axis=1)\n",
    "train_corr = labeled_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features most highly correlated with the label\n",
    "display(train_corr['target'].sort_values(ascending=False)[1:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of features above are the training features that are most-correlated with the training labels. Intuitively, I expect these features to be the most important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save h5 files\n",
    "def saveh5(fname, data, dname):\n",
    "    h5f = h5py.File(fname, 'w')\n",
    "    h5f.create_dataset(dname, data=data)\n",
    "    h5f.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pickle file\n",
    "def savepickle(fname, data):\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pkl.dump(data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed dataset (constant columns and duplicate columns removed):\n",
    "saveh5('../data/train_s0_vanilla.h5', labeled_train, 'train_s0')\n",
    "saveh5('../data/test_s0_vanilla.h5', test_df, 'test_s0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and test indexes\n",
    "savepickle('../data/train_idx.pkl', labeled_train.index.values)\n",
    "savepickle('../data/test_idx.pkl', test_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and test column names\n",
    "savepickle('../data/train_cols.pkl', labeled_train.columns.values)\n",
    "savepickle('../data/test_cols.pkl', test_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA:\n",
    "Performing PCA on the combined training and test set will allow me to visualize the percentage of variance explained for all features in the dataset. By determining which features don't contribute much information, I can further trim the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_df, test_df], axis=0)\n",
    "print('Shape of all data: {} Rows, {} Columns'.format(*all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA model\n",
    "pca = PCA()\n",
    "pca.fit(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(ratios)\n",
    "plt.title('Explained Variance Plot for All Data')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.yticks(np.arange(0, 1.2, step=0.1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of explained variance for both train and test data show that the first **3000** features account for 95% of the variance in both datasets. This will be information that I'll use in subsequent preprocessing efforts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Training Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(np.log1p(labels), color='green', kde=True, bins=100)\n",
    "plt.title('Distribution of log(target) Values')\n",
    "plt.xlabel('log(target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
