{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Reconstruction\n",
    "After verifying the Kaggle community's selection of important features, I will proceed to reconstruct the time-series dataset. Reconstruction will be based on this public kernel: https://www.kaggle.com/johnfarrell/breaking-lb-fresh-start-with-lag-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading h5py file\n",
    "def load_h5py(fname):\n",
    "    with h5py.File(fname, 'r') as handle:\n",
    "        return handle['data'][:]\n",
    "# Function for loading pickle file\n",
    "def load_pickle(fname):\n",
    "    with open(fname, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for setting up\n",
    "def get_input(debug=False):\n",
    "    '''\n",
    "    Function for loading either debug or full datasets\n",
    "    '''\n",
    "    os.chdir('../../data/compressed/')\n",
    "    print os.getcwd()\n",
    "    pkl_files = ['train_id.pickle', 'trainidx.pickle', 'target.pickle', 'test_id.pickle', 'testidx.pickle']\n",
    "    if debug:\n",
    "        print 'Loading debug train and test datasets...'\n",
    "        # h5py files\n",
    "        train = load_h5py('debug_train.h5')\n",
    "        test = load_h5py('debug_test.h5')\n",
    "        # pickle files\n",
    "        id_train, train_idx, target, id_test, test_idx = [load_pickle('debug_%s'%f) for f in pkl_files]\n",
    "    else:\n",
    "        print 'Loading original train and test datasets...'\n",
    "        # h5py files\n",
    "        train = load_h5py('full_train.h5')\n",
    "        test = load_h5py('full_test.h5')\n",
    "        # pickle files\n",
    "        id_train, train_idx, target, id_test, test_idx = [load_pickle('full_%s'%f) for f in pkl_files]\n",
    "    # Load feature names\n",
    "    fnames = load_pickle('feature_names.pickle')\n",
    "    # Find shape of loaded datasets\n",
    "    print('Shape of training dataset: {} Rows, {} Columns'.format(*train.shape))\n",
    "    print('Shape of test dataset: {} Rows, {} Columns'.format(*test.shape))\n",
    "    os.chdir('../../scripts/time_series/')\n",
    "    print os.getcwd()\n",
    "    return fnames, train, id_train, train_idx, target, test, id_test, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting datasets in dataframe format\n",
    "def get_dataframes(debug=False):\n",
    "    # Load data\n",
    "    fnames, train, id_train, train_idx, target, test, id_test, test_idx = get_input(debug)\n",
    "    # Format data\n",
    "    train_df = pd.DataFrame(data=train, index=train_idx, columns=fnames)\n",
    "    train_df['ID'] = id_train\n",
    "    train_df['target'] = target\n",
    "    test_df = pd.DataFrame(data=test, index=test_idx, columns=fnames)\n",
    "    test_df['ID'] = id_test\n",
    "    test_df['target'] = train_df['target'].mean()\n",
    "    \n",
    "    print('\\nShape of training dataframe: {} Rows, {} Columns'.format(*train_df.shape))\n",
    "    print('Shape of test dataframe: {} Rows, {} Columns'.format(*test_df.shape))\n",
    "    return fnames, train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting predictions with certain lag assumption\n",
    "def _get_leak(df, cols, lag=0):\n",
    "    # All columns except last two + lag into tuple\n",
    "    d1 = df[cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    # All columns except first two + lag into tuple\n",
    "    d2 = df[cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = df[cols[lag]]\n",
    "    # Remove duplicate keys so that join operation will work\n",
    "    d3 = d2[~d2.duplicated(subset=['key'], keep=False)]\n",
    "    # Return 'pred' result of d1 and d3 \n",
    "    return d1.merge(d3, how='left', on='key')['pred'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for rewriting leaky dataset UP TO best leak value\n",
    "def rewrite_compiled_leak(leak_df, lag):\n",
    "    # Reset compiled_leak field\n",
    "    leak_df['compiled_leak'] = 0\n",
    "    for i in range(lag):\n",
    "        c = 'leaked_target_%s'%str(i)\n",
    "        zeroleak = leak_df['compiled_leak']==0\n",
    "        leak_df.loc[zeroleak, 'compiled_leak'] = leak_df.loc[zeroleak, c]\n",
    "    return leak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cheng-haotai/Projects_Data/santander-value-prediction/data/compressed\n",
      "Loading original train and test datasets...\n",
      "Shape of training dataset: 4459 Rows, 4991 Columns\n",
      "Shape of test dataset: 49342 Rows, 4991 Columns\n",
      "/Users/cheng-haotai/Projects_Data/santander-value-prediction/scripts/time_series\n",
      "\n",
      "Shape of training dataframe: 4459 Rows, 4993 Columns\n",
      "Shape of test dataframe: 49342 Rows, 4993 Columns\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del fnames, train, test\n",
    "    print 'Clearing loaded dataframes from memory...\\n'\n",
    "except:\n",
    "    pass\n",
    "fnames, train, test = get_dataframes(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load important features\n",
    "cols = load_pickle('./important.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format target\n",
    "y = np.log1p(train['target']).values\n",
    "log_mean = y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Leak Compilation:\n",
    "**IMPORTANT:** This entire leak compilation procedure heavily relies upon the candidate time-series features being ordered such that they are in the proper time-series format.\n",
    "\n",
    "The Kaggle community refers to **leak** as the concept of forecasting the target value based on the time-series nature of the Santander dataset. Since the columns and rows of the Santander dataset are scrambled time-series features, it becomes possible to make predictions on the target variable solely by setting them equal to the values of another time-series feature. The candidate time-series features for this replacement operation have been identified by the Kaggle community and subsequently partially-validated by me in a separate analysis. \n",
    "\n",
    "The nature of this leak is demonstrated in one of the Kaggle community's public kernels: https://www.kaggle.com/johnfarrell/giba-s-property-extended-extended-result. \n",
    "\n",
    "In this public kernel, it can be seen that (given that the important features are ordered in the proper time-series fashion) the target variable is simply the generated time-series at a **lag of 2**. As such, it can be assumed that this **2** lag value is an important artifact of the dataset that can be used for making predictions of the target variable.\n",
    "\n",
    "This lag value is accounted-for in the **get_leak** function. The **get_leak** function details an algorithm for finding an appropriate forecast for the target variable, given a certain lag value (default of 2). This function takes the ordered time series data, creates two different sets of tuples consisting of the ordered data spliced at two separate ends, and compares these tuple sets for matches. The general motivation behind this algorithm is rooted in the idea that the target variable is equivalent to values within the important features, but with a time offset (2, as was shown in the linked public kernel above). \n",
    "\n",
    "Assuming that the ordering produced by the Kaggle community is correct, then snipping samples at both ends and searching for any matches through a join operation is essentially the same as checking if any particular sample is part of a longer sequence. If it is part of a longer sequence, then we can exercise the foundational assumption that the target variable is simply a temporal offset of the time-series and set the target variable to a value of 2 time offsets prior to the beginning of the sequence.\n",
    "\n",
    "This process is repeated for many lag values from 2 (default) until 38 (the number of important columns subtracted by 2). The reason why different lag values are used is because it is entirely possible that these 40 important features identified are not enough to fully represent the time-series when extended to the entire dataset. (Keep in mind that the tables shown in the above linked public kernel are only of a few select samples out of the entire dataset.) \n",
    "\n",
    "When extrapolated to the entire dataset, these 40 important features most likely have discontinuous time steps which is indicative of incomplete time seqeunces. As such, it is important to consider shorter segments when creating matches so that these incomplete time sequences can still have predictive value. That being said, longer sequences (shorter lag) have an inherently better predictive value and their predictions are prioritized over the shorter sequences (longer lag).\n",
    "\n",
    "As such, the leak compilation procedure aims to make predictions on the target variable by searching for sequence matches that can be used to leverage the **2-lag** behavior of the Santander dataset. Longer sequence matches are given higher priority than shorter sequence matches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leak Compilation for Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cols = ['compiled_leak', 'nonzero_mean']\n",
    "\n",
    "# Function for compiling leak results over many lag values\n",
    "def compiled_leak_result():\n",
    "    # Define number of lag values to consider\n",
    "    max_nlags = len(cols)-2\n",
    "    # Define leaky train set\n",
    "    train_leak = train[['ID', 'target'] + list(cols)]\n",
    "    # Initialize compiled_leak as zeros\n",
    "    train_leak['compiled_leak'] = 0\n",
    "    train_leak['nonzero_mean'] = train[fnames].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\n",
    "    # Initialize empty lists\n",
    "    scores = []\n",
    "    leaky_value_counts = []\n",
    "    leaky_value_corrects = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = 'leaked_target_%s'%str(i)\n",
    "        \n",
    "        print '\\nProcessing Lag:', i\n",
    "        # Get predictions for current lag and store in new column\n",
    "        train_leak[c] = _get_leak(train_leak, cols, i)\n",
    "        # Update leaky_cols with latest lag label\n",
    "        leaky_cols.append(c)\n",
    "        # Get \"grounding\" by joining with original training dataset\n",
    "        train_leak = train.join(train_leak.set_index('ID')[leaky_cols + extra_cols], \n",
    "                                on='ID', how='left')[['ID', 'target'] + list(cols) + leaky_cols + extra_cols]\n",
    "        # Iteratively fill in compiled_leak values for increasing lag\n",
    "        zeroleak = train_leak['compiled_leak'] == 0\n",
    "        train_leak.loc[zeroleak, 'compiled_leak'] = train_leak.loc[zeroleak, c]\n",
    "        \n",
    "        # Number of leaky values found so far\n",
    "        leaky_value_counts.append(np.sum(train_leak['compiled_leak']>0))\n",
    "        # Number of correct discovered leaky values\n",
    "        _correct_counts = np.sum(train_leak['compiled_leak']==train_leak['target'])\n",
    "        # Percentage of correct discovered leaky values\n",
    "        leaky_value_corrects.append(1.0*_correct_counts/leaky_value_counts[-1])\n",
    "        \n",
    "        print 'Number of leak values found in train:', leaky_value_counts[-1]\n",
    "        print 'Percentage of correct leak values in train:', leaky_value_corrects[-1]\n",
    "        \n",
    "        # Find score of current compilation iteration\n",
    "        tmp = train_leak.copy()  # Temporary dataframe\n",
    "        tmp.loc[zeroleak, 'compiled_leak'] = tmp.loc[zeroleak, 'nonzero_mean']\n",
    "        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp['compiled_leak']).fillna(log_mean))))\n",
    "        \n",
    "        print 'Score (filled with nonzero mean):', scores[-1]\n",
    "    \n",
    "    # End of iterations\n",
    "    result = dict(score=scores,\n",
    "                  leaky_count = leaky_value_counts,\n",
    "                  leaky_correct = leaky_value_corrects)\n",
    "    \n",
    "    return train_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Lag: 0\n",
      "Number of leak values found in train: 1351\n",
      "Percentage of correct leak values in train: 0.9955588453\n",
      "Score (filled with nonzero mean): 1.5138333391635188\n",
      "\n",
      "Processing Lag: 1\n",
      "Number of leak values found in train: 1947\n",
      "Percentage of correct leak values in train: 0.996404725218\n",
      "Score (filled with nonzero mean): 1.2922048129527162\n",
      "\n",
      "Processing Lag: 2\n",
      "Number of leak values found in train: 2340\n",
      "Percentage of correct leak values in train: 0.99358974359\n",
      "Score (filled with nonzero mean): 1.1732829046778304\n",
      "\n",
      "Processing Lag: 3\n",
      "Number of leak values found in train: 2586\n",
      "Percentage of correct leak values in train: 0.993039443155\n",
      "Score (filled with nonzero mean): 1.084326373672634\n",
      "\n",
      "Processing Lag: 4\n",
      "Number of leak values found in train: 2754\n",
      "Percentage of correct leak values in train: 0.993464052288\n",
      "Score (filled with nonzero mean): 1.0327870440015579\n",
      "\n",
      "Processing Lag: 5\n",
      "Number of leak values found in train: 2899\n",
      "Percentage of correct leak values in train: 0.993101069334\n",
      "Score (filled with nonzero mean): 0.9940324299498775\n",
      "\n",
      "Processing Lag: 6\n",
      "Number of leak values found in train: 3014\n",
      "Percentage of correct leak values in train: 0.992368944924\n",
      "Score (filled with nonzero mean): 0.9475716466467444\n",
      "\n",
      "Processing Lag: 7\n",
      "Number of leak values found in train: 3110\n",
      "Percentage of correct leak values in train: 0.991961414791\n",
      "Score (filled with nonzero mean): 0.9061425741761028\n",
      "\n",
      "Processing Lag: 8\n",
      "Number of leak values found in train: 3188\n",
      "Percentage of correct leak values in train: 0.991844416562\n",
      "Score (filled with nonzero mean): 0.8829375962288963\n",
      "\n",
      "Processing Lag: 9\n",
      "Number of leak values found in train: 3237\n",
      "Percentage of correct leak values in train: 0.991658943466\n",
      "Score (filled with nonzero mean): 0.8645425426899049\n",
      "\n",
      "Processing Lag: 10\n",
      "Number of leak values found in train: 3296\n",
      "Percentage of correct leak values in train: 0.991504854369\n",
      "Score (filled with nonzero mean): 0.8514676567599474\n",
      "\n",
      "Processing Lag: 11\n",
      "Number of leak values found in train: 3336\n",
      "Percentage of correct leak values in train: 0.991606714628\n",
      "Score (filled with nonzero mean): 0.8372610483023677\n",
      "\n",
      "Processing Lag: 12\n",
      "Number of leak values found in train: 3382\n",
      "Percentage of correct leak values in train: 0.990242460083\n",
      "Score (filled with nonzero mean): 0.8214331403442912\n",
      "\n",
      "Processing Lag: 13\n",
      "Number of leak values found in train: 3416\n",
      "Percentage of correct leak values in train: 0.990046838407\n",
      "Score (filled with nonzero mean): 0.8154372338396488\n",
      "\n",
      "Processing Lag: 14\n",
      "Number of leak values found in train: 3450\n",
      "Percentage of correct leak values in train: 0.990144927536\n",
      "Score (filled with nonzero mean): 0.8038791462519903\n",
      "\n",
      "Processing Lag: 15\n",
      "Number of leak values found in train: 3470\n",
      "Percentage of correct leak values in train: 0.989913544669\n",
      "Score (filled with nonzero mean): 0.7918901526062938\n",
      "\n",
      "Processing Lag: 16\n",
      "Number of leak values found in train: 3489\n",
      "Percentage of correct leak values in train: 0.98939524219\n",
      "Score (filled with nonzero mean): 0.7909669836528118\n",
      "\n",
      "Processing Lag: 17\n",
      "Number of leak values found in train: 3511\n",
      "Percentage of correct leak values in train: 0.989461691826\n",
      "Score (filled with nonzero mean): 0.7873456935780921\n",
      "\n",
      "Processing Lag: 18\n",
      "Number of leak values found in train: 3528\n",
      "Percentage of correct leak values in train: 0.989229024943\n",
      "Score (filled with nonzero mean): 0.7796162154931962\n",
      "\n",
      "Processing Lag: 19\n",
      "Number of leak values found in train: 3544\n",
      "Percentage of correct leak values in train: 0.98927765237\n",
      "Score (filled with nonzero mean): 0.7746425745753255\n",
      "\n",
      "Processing Lag: 20\n",
      "Number of leak values found in train: 3556\n",
      "Percentage of correct leak values in train: 0.989313835771\n",
      "Score (filled with nonzero mean): 0.7687755528095325\n",
      "\n",
      "Processing Lag: 21\n",
      "Number of leak values found in train: 3573\n",
      "Percentage of correct leak values in train: 0.988245172124\n",
      "Score (filled with nonzero mean): 0.7598294446703147\n",
      "\n",
      "Processing Lag: 22\n",
      "Number of leak values found in train: 3583\n",
      "Percentage of correct leak values in train: 0.987998883617\n",
      "Score (filled with nonzero mean): 0.7526327532075344\n",
      "\n",
      "Processing Lag: 23\n",
      "Number of leak values found in train: 3595\n",
      "Percentage of correct leak values in train: 0.98776077886\n",
      "Score (filled with nonzero mean): 0.7497264357981446\n",
      "\n",
      "Processing Lag: 24\n",
      "Number of leak values found in train: 3605\n",
      "Percentage of correct leak values in train: 0.986962552011\n",
      "Score (filled with nonzero mean): 0.7444695955337373\n",
      "\n",
      "Processing Lag: 25\n",
      "Number of leak values found in train: 3611\n",
      "Percentage of correct leak values in train: 0.986984214899\n",
      "Score (filled with nonzero mean): 0.7443442780627189\n",
      "\n",
      "Processing Lag: 26\n",
      "Number of leak values found in train: 3622\n",
      "Percentage of correct leak values in train: 0.985919381557\n",
      "Score (filled with nonzero mean): 0.7424266698188009\n",
      "\n",
      "Processing Lag: 27\n",
      "Number of leak values found in train: 3628\n",
      "Percentage of correct leak values in train: 0.985667034179\n",
      "Score (filled with nonzero mean): 0.7408904201985931\n",
      "\n",
      "Processing Lag: 28\n",
      "Number of leak values found in train: 3633\n",
      "Percentage of correct leak values in train: 0.985411505643\n",
      "Score (filled with nonzero mean): 0.7376835453405299\n",
      "\n",
      "Processing Lag: 29\n",
      "Number of leak values found in train: 3637\n",
      "Percentage of correct leak values in train: 0.984602694528\n",
      "Score (filled with nonzero mean): 0.7371911838169722\n",
      "\n",
      "Processing Lag: 30\n",
      "Number of leak values found in train: 3644\n",
      "Percentage of correct leak values in train: 0.983260153677\n",
      "Score (filled with nonzero mean): 0.7394311615490368\n",
      "\n",
      "Processing Lag: 31\n",
      "Number of leak values found in train: 3647\n",
      "Percentage of correct leak values in train: 0.98245132986\n",
      "Score (filled with nonzero mean): 0.7388315249909508\n",
      "\n",
      "Processing Lag: 32\n",
      "Number of leak values found in train: 3650\n",
      "Percentage of correct leak values in train: 0.981643835616\n",
      "Score (filled with nonzero mean): 0.7393381067031505\n",
      "\n",
      "Processing Lag: 33\n",
      "Number of leak values found in train: 3660\n",
      "Percentage of correct leak values in train: 0.979508196721\n",
      "Score (filled with nonzero mean): 0.7402421029724673\n",
      "\n",
      "Processing Lag: 34\n",
      "Number of leak values found in train: 3662\n",
      "Percentage of correct leak values in train: 0.97924631349\n",
      "Score (filled with nonzero mean): 0.7398911272837492\n",
      "\n",
      "Processing Lag: 35\n",
      "Number of leak values found in train: 3663\n",
      "Percentage of correct leak values in train: 0.978978978979\n",
      "Score (filled with nonzero mean): 0.7404147171102295\n",
      "\n",
      "Processing Lag: 36\n",
      "Number of leak values found in train: 3666\n",
      "Percentage of correct leak values in train: 0.978177850518\n",
      "Score (filled with nonzero mean): 0.7432607190143065\n",
      "\n",
      "Processing Lag: 37\n",
      "Number of leak values found in train: 3666\n",
      "Percentage of correct leak values in train: 0.978177850518\n",
      "Score (filled with nonzero mean): 0.7427450896821166\n"
     ]
    }
   ],
   "source": [
    "# Get leaked training data and result\n",
    "train_leak, result = compiled_leak_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leaky_correct</th>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.996405</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>0.993039</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>0.992369</td>\n",
       "      <td>0.991961</td>\n",
       "      <td>0.991844</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985412</td>\n",
       "      <td>0.984603</td>\n",
       "      <td>0.983260</td>\n",
       "      <td>0.982451</td>\n",
       "      <td>0.981644</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>0.978178</td>\n",
       "      <td>0.978178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaky_count</th>\n",
       "      <td>1351.000000</td>\n",
       "      <td>1947.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2586.000000</td>\n",
       "      <td>2754.000000</td>\n",
       "      <td>2899.000000</td>\n",
       "      <td>3014.000000</td>\n",
       "      <td>3110.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3633.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3644.000000</td>\n",
       "      <td>3647.000000</td>\n",
       "      <td>3650.000000</td>\n",
       "      <td>3660.000000</td>\n",
       "      <td>3662.000000</td>\n",
       "      <td>3663.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "      <td>3666.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.513833</td>\n",
       "      <td>1.292205</td>\n",
       "      <td>1.173283</td>\n",
       "      <td>1.084326</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>0.994032</td>\n",
       "      <td>0.947572</td>\n",
       "      <td>0.906143</td>\n",
       "      <td>0.882938</td>\n",
       "      <td>0.864543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737684</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.739431</td>\n",
       "      <td>0.738832</td>\n",
       "      <td>0.739338</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.739891</td>\n",
       "      <td>0.740415</td>\n",
       "      <td>0.743261</td>\n",
       "      <td>0.742745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0            1            2            3   \\\n",
       "leaky_correct     0.995559     0.996405     0.993590     0.993039   \n",
       "leaky_count    1351.000000  1947.000000  2340.000000  2586.000000   \n",
       "score             1.513833     1.292205     1.173283     1.084326   \n",
       "\n",
       "                        4            5            6            7   \\\n",
       "leaky_correct     0.993464     0.993101     0.992369     0.991961   \n",
       "leaky_count    2754.000000  2899.000000  3014.000000  3110.000000   \n",
       "score             1.032787     0.994032     0.947572     0.906143   \n",
       "\n",
       "                        8            9      ...                28  \\\n",
       "leaky_correct     0.991844     0.991659     ...          0.985412   \n",
       "leaky_count    3188.000000  3237.000000     ...       3633.000000   \n",
       "score             0.882938     0.864543     ...          0.737684   \n",
       "\n",
       "                        29           30           31           32  \\\n",
       "leaky_correct     0.984603     0.983260     0.982451     0.981644   \n",
       "leaky_count    3637.000000  3644.000000  3647.000000  3650.000000   \n",
       "score             0.737191     0.739431     0.738832     0.739338   \n",
       "\n",
       "                        33           34           35           36           37  \n",
       "leaky_correct     0.979508     0.979246     0.978979     0.978178     0.978178  \n",
       "leaky_count    3660.000000  3662.000000  3663.000000  3666.000000  3666.000000  \n",
       "score             0.740242     0.739891     0.740415     0.743261     0.742745  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format results \n",
    "result = pd.DataFrame.from_dict(result, orient='columns')\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "train_res_name = './stats/train_leaky_stat.csv'\n",
    "result.to_csv(train_res_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7371911838169722\n",
      "Best lag value: 29\n"
     ]
    }
   ],
   "source": [
    "# Find best score and lag value\n",
    "best_score = np.min(result['score'])\n",
    "best_lag = np.argmin(result['score'])\n",
    "print 'Best score:', best_score\n",
    "print 'Best lag value:', best_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite leaky training set in terms of best lag\n",
    "leaky_cols = [c for c in train_leak.columns if 'leaked_target_' in c]\n",
    "train_leak = rewrite_compiled_leak(train_leak, best_lag)\n",
    "\n",
    "train_leak_name = './stats/train_leak.csv'\n",
    "# Save train_leak\n",
    "train_res = train_leak[leaky_cols + ['compiled_leak']].replace(0.0, np.nan)\n",
    "train_res.to_csv(train_leak_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leak Compilation for Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for compiling leaky values for test set\n",
    "def compiled_leak_result_test():\n",
    "    max_nlags = len(cols)-2\n",
    "    \n",
    "    test_leak = test[['ID', 'target'] + list(cols)]\n",
    "    test_leak['compiled_leak'] = 0\n",
    "    test_leak['nonzero_mean'] = test[fnames].apply(lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1)\n",
    "    \n",
    "    leaky_value_counts = []\n",
    "    leaky_cols = []\n",
    "    \n",
    "    for i in range(max_nlags):\n",
    "        c = 'leaked_target_%s'%str(i)\n",
    "        \n",
    "        print '\\nProcessing Lag:', i\n",
    "        test_leak[c] = _get_leak(test_leak, cols, i)\n",
    "        leaky_cols.append(c)\n",
    "        \n",
    "        test_leak = test.join(test_leak.set_index('ID')[leaky_cols + extra_cols], \n",
    "                              on='ID', how='left')[['ID', 'target'] + list(cols) + leaky_cols + extra_cols]\n",
    "        zeroleak = test_leak['compiled_leak']==0\n",
    "        test_leak.loc[zeroleak, 'compiled_leak'] = test_leak.loc[zeroleak, c]\n",
    "        leaky_value_counts.append(np.sum(test_leak['compiled_leak']>0))\n",
    "        \n",
    "        print 'Number of leaky values found in test:', leaky_value_counts[-1]\n",
    "        \n",
    "    # End iterations\n",
    "    result = dict(leaky_count = leaky_value_counts)\n",
    "    \n",
    "    return test_leak, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Lag: 0\n",
      "Number of leaky values found in test: 2963\n",
      "\n",
      "Processing Lag: 1\n",
      "Number of leaky values found in test: 4215\n",
      "\n",
      "Processing Lag: 2\n",
      "Number of leaky values found in test: 4960\n",
      "\n",
      "Processing Lag: 3\n",
      "Number of leaky values found in test: 5503\n",
      "\n",
      "Processing Lag: 4\n",
      "Number of leaky values found in test: 5917\n",
      "\n",
      "Processing Lag: 5\n",
      "Number of leaky values found in test: 6208\n",
      "\n",
      "Processing Lag: 6\n",
      "Number of leaky values found in test: 6426\n",
      "\n",
      "Processing Lag: 7\n",
      "Number of leaky values found in test: 6583\n",
      "\n",
      "Processing Lag: 8\n",
      "Number of leaky values found in test: 6742\n",
      "\n",
      "Processing Lag: 9\n",
      "Number of leaky values found in test: 6872\n",
      "\n",
      "Processing Lag: 10\n",
      "Number of leaky values found in test: 6983\n",
      "\n",
      "Processing Lag: 11\n",
      "Number of leaky values found in test: 7080\n",
      "\n",
      "Processing Lag: 12\n",
      "Number of leaky values found in test: 7159\n",
      "\n",
      "Processing Lag: 13\n",
      "Number of leaky values found in test: 7243\n",
      "\n",
      "Processing Lag: 14\n",
      "Number of leaky values found in test: 7303\n",
      "\n",
      "Processing Lag: 15\n",
      "Number of leaky values found in test: 7366\n",
      "\n",
      "Processing Lag: 16\n",
      "Number of leaky values found in test: 7420\n",
      "\n",
      "Processing Lag: 17\n",
      "Number of leaky values found in test: 7462\n",
      "\n",
      "Processing Lag: 18\n",
      "Number of leaky values found in test: 7499\n",
      "\n",
      "Processing Lag: 19\n",
      "Number of leaky values found in test: 7540\n",
      "\n",
      "Processing Lag: 20\n",
      "Number of leaky values found in test: 7581\n",
      "\n",
      "Processing Lag: 21\n",
      "Number of leaky values found in test: 7617\n",
      "\n",
      "Processing Lag: 22\n",
      "Number of leaky values found in test: 7658\n",
      "\n",
      "Processing Lag: 23\n",
      "Number of leaky values found in test: 7689\n",
      "\n",
      "Processing Lag: 24\n",
      "Number of leaky values found in test: 7717\n",
      "\n",
      "Processing Lag: 25\n",
      "Number of leaky values found in test: 7748\n",
      "\n",
      "Processing Lag: 26\n",
      "Number of leaky values found in test: 7773\n",
      "\n",
      "Processing Lag: 27\n",
      "Number of leaky values found in test: 7803\n",
      "\n",
      "Processing Lag: 28\n",
      "Number of leaky values found in test: 7835\n",
      "\n",
      "Processing Lag: 29\n",
      "Number of leaky values found in test: 7887\n",
      "\n",
      "Processing Lag: 30\n",
      "Number of leaky values found in test: 7949\n",
      "\n",
      "Processing Lag: 31\n",
      "Number of leaky values found in test: 8025\n",
      "\n",
      "Processing Lag: 32\n",
      "Number of leaky values found in test: 8117\n",
      "\n",
      "Processing Lag: 33\n",
      "Number of leaky values found in test: 8277\n",
      "\n",
      "Processing Lag: 34\n",
      "Number of leaky values found in test: 8478\n",
      "\n",
      "Processing Lag: 35\n",
      "Number of leaky values found in test: 8685\n",
      "\n",
      "Processing Lag: 36\n",
      "Number of leaky values found in test: 9012\n",
      "\n",
      "Processing Lag: 37\n",
      "Number of leaky values found in test: 9501\n"
     ]
    }
   ],
   "source": [
    "# Get leaked test data and result\n",
    "test_leak, test_result = compiled_leak_result_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leaky_count</th>\n",
       "      <td>2963</td>\n",
       "      <td>4215</td>\n",
       "      <td>4960</td>\n",
       "      <td>5503</td>\n",
       "      <td>5917</td>\n",
       "      <td>6208</td>\n",
       "      <td>6426</td>\n",
       "      <td>6583</td>\n",
       "      <td>6742</td>\n",
       "      <td>6872</td>\n",
       "      <td>...</td>\n",
       "      <td>7835</td>\n",
       "      <td>7887</td>\n",
       "      <td>7949</td>\n",
       "      <td>8025</td>\n",
       "      <td>8117</td>\n",
       "      <td>8277</td>\n",
       "      <td>8478</td>\n",
       "      <td>8685</td>\n",
       "      <td>9012</td>\n",
       "      <td>9501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9   ...   \\\n",
       "leaky_count  2963  4215  4960  5503  5917  6208  6426  6583  6742  6872  ...    \n",
       "\n",
       "               28    29    30    31    32    33    34    35    36    37  \n",
       "leaky_count  7835  7887  7949  8025  8117  8277  8478  8685  9012  9501  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format test results\n",
    "test_result = pd.DataFrame.from_dict(test_result, orient='columns')\n",
    "test_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test results\n",
    "test_res_name  = './stats/test_leaky_stat.csv'\n",
    "test_result.to_csv(test_res_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite leaky test set in terms of best lag\n",
    "test_leak = rewrite_compiled_leak(test_leak, best_lag)\n",
    "\n",
    "test_leak_name = './stats/test_leak.csv'\n",
    "# Save test_leak\n",
    "test_res = test_leak[leaky_cols + ['compiled_leak']].replace(0.0, np.nan)\n",
    "test_res.to_csv(test_leak_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros in compiled_leak field\n",
    "test_leak.loc[test_leak['compiled_leak']==0, 'compiled_leak'] = test_leak.loc[test_leak['compiled_leak']==0, \n",
    "                                                                              'nonzero_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_name = '../../submissions/recon_0_lag%s_submit.csv'%best_lag\n",
    "# Make and save submission\n",
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test['ID']\n",
    "sub['target'] = test_leak['compiled_leak']\n",
    "sub.to_csv(submit_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>2.209645e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>1.099644e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>1.276252e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>7.871320e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>2.868883e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID        target\n",
       "0  000137c73  2.209645e+06\n",
       "1  00021489f  1.099644e+06\n",
       "2  0004d7953  1.276252e+06\n",
       "3  00056a333  7.871320e+06\n",
       "4  00056d8eb  2.868883e+06"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
